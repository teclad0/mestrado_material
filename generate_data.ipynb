{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40965227",
   "metadata": {},
   "source": [
    "# A Jupyter Notebook for Dataset Generation\n",
    "This notebook demonstrates how to generate datasets using SCAR, SAR, and PG labeling mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c87c1",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Import the necessary libraries, including NumPy and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43e4131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7b190",
   "metadata": {},
   "source": [
    "## Set Random Seed\n",
    "Set a random seed using NumPy for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f8f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195c992",
   "metadata": {},
   "source": [
    "## Define Parameters\n",
    "Define the parameters for the positive and negative distributions, including means and covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450e745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples for each class\n",
    "n_samples = 20\n",
    "n_labeled_positive = 5\n",
    "\n",
    "# Define the parameters for the positive and negative distributions\n",
    "positive_mean = [1, 1]\n",
    "positive_cov = [[1, 0], [0, 1]]\n",
    "negative_mean = [-1, -1]\n",
    "negative_cov = [[1, 0], [0, 1]]\n",
    "\n",
    "dict_label = {'positive': 1, 'unlabeled': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f49343",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "Generate true positive and negative samples using NumPy's multivariate_normal function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622e8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate true positive and negative samples\n",
    "true_positives = np.random.multivariate_normal(positive_mean, positive_cov, n_samples)\n",
    "true_negatives = np.random.multivariate_normal(negative_mean, negative_cov, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e2694",
   "metadata": {},
   "source": [
    "## Create SCAR Dataset\n",
    "Generate the SCAR dataset by randomly labeling a subset of positive samples and combining them with unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1a4911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCAR Dataset:\n",
      "    feature_1  feature_2 true_label observed_label\n",
      "0    1.496714   0.861736   positive       positive\n",
      "1    1.647689   2.523030   positive      unlabeled\n",
      "2    0.765847   0.765863   positive      unlabeled\n",
      "3    2.579213   1.767435   positive      unlabeled\n",
      "4    0.530526   1.542560   positive      unlabeled\n",
      "5    0.536582   0.534270   positive      unlabeled\n",
      "6    1.241962  -0.913280   positive      unlabeled\n",
      "7   -0.724918   0.437712   positive       positive\n",
      "8   -0.012831   1.314247   positive       positive\n",
      "9    0.091976  -0.412304   positive       positive\n",
      "10   2.465649   0.774224   positive      unlabeled\n",
      "11   1.067528  -0.424748   positive      unlabeled\n",
      "12   0.455617   1.110923   positive      unlabeled\n",
      "13  -0.150994   1.375698   positive      unlabeled\n",
      "14   0.399361   0.708306   positive      unlabeled\n",
      "15   0.398293   2.852278   positive      unlabeled\n",
      "16   0.986503  -0.057711   positive      unlabeled\n",
      "17   1.822545  -0.220844   positive      unlabeled\n",
      "18   1.208864  -0.959670   positive      unlabeled\n",
      "19  -0.328186   1.196861   positive       positive\n",
      "20  -0.261533  -0.828632   negative      unlabeled\n",
      "21  -1.115648  -1.301104   negative      unlabeled\n",
      "22  -2.478522  -1.719844   negative      unlabeled\n",
      "23  -1.460639   0.057122   negative      unlabeled\n",
      "24  -0.656382  -2.763040   negative      unlabeled\n",
      "25  -0.675916  -1.385082   negative      unlabeled\n",
      "26  -1.676922  -0.388324   negative      unlabeled\n",
      "27   0.031000  -0.068720   negative      unlabeled\n",
      "28  -1.839218  -1.309212   negative      unlabeled\n",
      "29  -0.668737  -0.024455   negative      unlabeled\n",
      "30  -1.479174  -1.185659   negative      unlabeled\n",
      "31  -2.106335  -2.196207   negative      unlabeled\n",
      "32  -0.187474   0.356240   negative      unlabeled\n",
      "33  -1.072010   0.003533   negative      unlabeled\n",
      "34  -0.638364  -1.645120   negative      unlabeled\n",
      "35  -0.638604   0.538037   negative      unlabeled\n",
      "36  -1.035826   0.564644   negative      unlabeled\n",
      "37  -3.619745  -0.178097   negative      unlabeled\n",
      "38  -0.912953  -1.299007   negative      unlabeled\n",
      "39  -0.908239  -2.987569   negative      unlabeled\n"
     ]
    }
   ],
   "source": [
    "# --- SCAR Dataset ---\n",
    "scar_labeled_indices = np.random.choice(n_samples, n_labeled_positive, replace=False)\n",
    "scar_labels = ['unlabeled'] * (2 * n_samples)\n",
    "scar_true_labels = ['positive'] * n_samples + ['negative'] * n_samples\n",
    "for i in scar_labeled_indices:\n",
    "    scar_labels[i] = 'positive'\n",
    "scar_data_scar = np.vstack((true_positives, true_negatives))\n",
    "scar_df = pd.DataFrame(scar_data_scar, columns=['feature_1', 'feature_2'])\n",
    "scar_df['true_label'] = scar_true_labels\n",
    "scar_df['observed_label'] = scar_labels\n",
    "\n",
    "print(\"\\nSCAR Dataset:\")\n",
    "print(scar_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c0959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scar_df['observed_label'] = scar_df['observed_label'].apply(lambda x: dict_label[x])\n",
    "scar_df.to_csv('data/scar_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2016e",
   "metadata": {},
   "source": [
    "## Create SAR Dataset\n",
    "Generate the SAR dataset by using a linear decision boundary to assign labeling probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b512589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAR Dataset:\n",
      "    feature_1  feature_2 true_label observed_label\n",
      "0    1.496714   0.861736   positive      unlabeled\n",
      "1    1.647689   2.523030   positive      unlabeled\n",
      "2    0.765847   0.765863   positive      unlabeled\n",
      "3    2.579213   1.767435   positive       positive\n",
      "4    0.530526   1.542560   positive      unlabeled\n",
      "5    0.536582   0.534270   positive      unlabeled\n",
      "6    1.241962  -0.913280   positive      unlabeled\n",
      "7   -0.724918   0.437712   positive      unlabeled\n",
      "8   -0.012831   1.314247   positive      unlabeled\n",
      "9    0.091976  -0.412304   positive      unlabeled\n",
      "10   2.465649   0.774224   positive       positive\n",
      "11   1.067528  -0.424748   positive      unlabeled\n",
      "12   0.455617   1.110923   positive      unlabeled\n",
      "13  -0.150994   1.375698   positive      unlabeled\n",
      "14   0.399361   0.708306   positive       positive\n",
      "15   0.398293   2.852278   positive      unlabeled\n",
      "16   0.986503  -0.057711   positive       positive\n",
      "17   1.822545  -0.220844   positive       positive\n",
      "18   1.208864  -0.959670   positive      unlabeled\n",
      "19  -0.328186   1.196861   positive      unlabeled\n",
      "20  -0.261533  -0.828632   negative      unlabeled\n",
      "21  -1.115648  -1.301104   negative      unlabeled\n",
      "22  -2.478522  -1.719844   negative      unlabeled\n",
      "23  -1.460639   0.057122   negative      unlabeled\n",
      "24  -0.656382  -2.763040   negative      unlabeled\n",
      "25  -0.675916  -1.385082   negative      unlabeled\n",
      "26  -1.676922  -0.388324   negative      unlabeled\n",
      "27   0.031000  -0.068720   negative      unlabeled\n",
      "28  -1.839218  -1.309212   negative      unlabeled\n",
      "29  -0.668737  -0.024455   negative      unlabeled\n",
      "30  -1.479174  -1.185659   negative      unlabeled\n",
      "31  -2.106335  -2.196207   negative      unlabeled\n",
      "32  -0.187474   0.356240   negative      unlabeled\n",
      "33  -1.072010   0.003533   negative      unlabeled\n",
      "34  -0.638364  -1.645120   negative      unlabeled\n",
      "35  -0.638604   0.538037   negative      unlabeled\n",
      "36  -1.035826   0.564644   negative      unlabeled\n",
      "37  -3.619745  -0.178097   negative      unlabeled\n",
      "38  -0.912953  -1.299007   negative      unlabeled\n",
      "39  -0.908239  -2.987569   negative      unlabeled\n"
     ]
    }
   ],
   "source": [
    "# --- SAR Dataset ---\n",
    "sar_true_labels = ['positive'] * n_samples + ['negative'] * n_samples\n",
    "sar_data_sar = np.vstack((true_positives, true_negatives))\n",
    "sar_labels = ['unlabeled'] * (2 * n_samples)\n",
    "\n",
    "# Define a simple linear decision boundary for SAR labeling probability\n",
    "weights = np.array([1, -1])\n",
    "bias = 0\n",
    "distances = np.dot(true_positives, weights) + bias\n",
    "probabilities = 1 / (1 + np.exp(-distances)) # Sigmoid function\n",
    "\n",
    "sar_labeled_indices = np.random.choice(n_samples, size=n_labeled_positive, replace=False, p=probabilities / np.sum(probabilities))\n",
    "for i in sar_labeled_indices:\n",
    "    sar_labels[i] = 'positive'\n",
    "\n",
    "sar_df = pd.DataFrame(sar_data_sar, columns=['feature_1', 'feature_2'])\n",
    "sar_df['true_label'] = sar_true_labels\n",
    "sar_df['observed_label'] = sar_labels\n",
    "\n",
    "print(\"\\nSAR Dataset:\")\n",
    "print(sar_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19e66b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_df['observed_label'] = sar_df['observed_label'].apply(lambda x: dict_label[x])\n",
    "sar_df.to_csv('data/sar_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6cac7",
   "metadata": {},
   "source": [
    "## Create PG Dataset\n",
    "Generate the PG dataset by labeling all positive samples and leaving negative samples unlabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d076da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PG Dataset:\n",
      "    feature_1  feature_2 true_label observed_label\n",
      "0    1.496714   0.861736   positive       positive\n",
      "1    1.647689   2.523030   positive       positive\n",
      "2    0.765847   0.765863   positive       positive\n",
      "3    2.579213   1.767435   positive       positive\n",
      "4    0.530526   1.542560   positive       positive\n",
      "5    0.536582   0.534270   positive       positive\n",
      "6    1.241962  -0.913280   positive       positive\n",
      "7   -0.724918   0.437712   positive       positive\n",
      "8   -0.012831   1.314247   positive       positive\n",
      "9    0.091976  -0.412304   positive       positive\n",
      "10   2.465649   0.774224   positive       positive\n",
      "11   1.067528  -0.424748   positive       positive\n",
      "12   0.455617   1.110923   positive       positive\n",
      "13  -0.150994   1.375698   positive       positive\n",
      "14   0.399361   0.708306   positive       positive\n",
      "15   0.398293   2.852278   positive       positive\n",
      "16   0.986503  -0.057711   positive       positive\n",
      "17   1.822545  -0.220844   positive       positive\n",
      "18   1.208864  -0.959670   positive       positive\n",
      "19  -0.328186   1.196861   positive       positive\n",
      "20  -0.261533  -0.828632   negative      unlabeled\n",
      "21  -1.115648  -1.301104   negative      unlabeled\n",
      "22  -2.478522  -1.719844   negative      unlabeled\n",
      "23  -1.460639   0.057122   negative      unlabeled\n",
      "24  -0.656382  -2.763040   negative      unlabeled\n",
      "25  -0.675916  -1.385082   negative      unlabeled\n",
      "26  -1.676922  -0.388324   negative      unlabeled\n",
      "27   0.031000  -0.068720   negative      unlabeled\n",
      "28  -1.839218  -1.309212   negative      unlabeled\n",
      "29  -0.668737  -0.024455   negative      unlabeled\n",
      "30  -1.479174  -1.185659   negative      unlabeled\n",
      "31  -2.106335  -2.196207   negative      unlabeled\n",
      "32  -0.187474   0.356240   negative      unlabeled\n",
      "33  -1.072010   0.003533   negative      unlabeled\n",
      "34  -0.638364  -1.645120   negative      unlabeled\n",
      "35  -0.638604   0.538037   negative      unlabeled\n",
      "36  -1.035826   0.564644   negative      unlabeled\n",
      "37  -3.619745  -0.178097   negative      unlabeled\n",
      "38  -0.912953  -1.299007   negative      unlabeled\n",
      "39  -0.908239  -2.987569   negative      unlabeled\n"
     ]
    }
   ],
   "source": [
    "# --- PG Dataset ---\n",
    "pg_true_labels = ['positive'] * n_samples + ['negative'] * n_samples\n",
    "pg_data_pg = np.vstack((true_positives, true_negatives))\n",
    "pg_labels = ['positive'] * n_samples + ['unlabeled'] * n_samples\n",
    "pg_df = pd.DataFrame(pg_data_pg, columns=['feature_1', 'feature_2'])\n",
    "pg_df['true_label'] = pg_true_labels\n",
    "pg_df['observed_label'] = pg_labels\n",
    "\n",
    "print(\"\\nPG Dataset:\")\n",
    "print(pg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15faede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_df['observed_label'] = pg_df['observed_label'].apply(lambda x: dict_label[x])\n",
    "pg_df.to_csv('data/pg_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
